{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffj-1mCf9YD8"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Input, Concatenate, Flatten\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y0kobKe9pPp",
        "outputId": "82b55b38-4bdf-4345-d262-6a59d6659b7c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to your dataset in Google Drive\n",
        "video_folder = '/content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips'\n",
        "transcription_folder = '/content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Transcription'\n",
        "gesture_annotation_file = '/content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Annotation/All_Gestures_Deceptive and Truthful.csv'"
      ],
      "metadata": {
        "id": "LJsVaNgf9xSa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load gesture annotations\n",
        "gesture_annotations = pd.read_csv(gesture_annotation_file)\n",
        "\n",
        "# Inspect the columns of the gesture_annotations DataFrame\n",
        "print(gesture_annotations.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-bVnpbwItwR",
        "outputId": "0314101e-7e5d-48cd-f79e-9c273dbe81b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'OtherGestures', 'Smile', 'Laugh', 'Scowl',\n",
            "       'otherEyebrowMovement', 'Frown', 'Raise', 'OtherEyeMovements',\n",
            "       'Close-R', 'X-Open', 'Close-BE', 'gazeInterlocutor', 'gazeDown',\n",
            "       'gazeUp', 'otherGaze', 'gazeSide', 'openMouth', 'closeMouth',\n",
            "       'lipsDown', 'lipsUp', 'lipsRetracted', 'lipsProtruded', 'SideTurn',\n",
            "       'downR', 'sideTilt', 'backHead', 'otherHeadM', 'sideTurnR', 'sideTiltR',\n",
            "       'waggle', 'forwardHead', 'downRHead', 'singleHand', 'bothHands',\n",
            "       'otherHandM', 'complexHandM', 'sidewaysHand', 'downHands', 'upHands',\n",
            "       'class'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the first column is the clip ID, and the last column is the label\n",
        "clip_id_column = gesture_annotations.columns[0]\n",
        "label_column = gesture_annotations.columns[-1]\n",
        "\n",
        "# Initialize pre-trained CNN for video feature extraction\n",
        "cnn_model = VGG16(weights='imagenet', include_top=False)\n",
        "cnn_model = Model(inputs=cnn_model.input, outputs=Flatten()(cnn_model.output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13jnVFhGIeQz",
        "outputId": "90b36e51-def8-4df7-b8b0-df1aa269dd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract video features\n",
        "def extract_video_features(video_path, cnn_model, fixed_frame_count=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    count = 0\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {video_path}\")\n",
        "        return None\n",
        "\n",
        "    while cap.isOpened() and count < fixed_frame_count:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, (224, 224))  # Resize frame to fit VGG16 input\n",
        "        frames.append(frame)\n",
        "        count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if len(frames) == 0:\n",
        "        print(f\"Error: No frames extracted from video file {video_path}\")\n",
        "        return None\n",
        "\n",
        "    # Pad frames if less than fixed_frame_count\n",
        "    while len(frames) < fixed_frame_count:\n",
        "        frames.append(np.zeros((224, 224, 3), dtype='float32'))\n",
        "\n",
        "    frames = np.array(frames)\n",
        "\n",
        "    # Preprocess frames for VGG16\n",
        "    frames = frames.astype('float32')\n",
        "    frames = frames / 255.0  # Normalize pixel values\n",
        "\n",
        "    # Extract features using the CNN\n",
        "    features = cnn_model.predict(frames)\n",
        "\n",
        "    # Average features across frames\n",
        "    video_features = np.mean(features, axis=0)\n",
        "\n",
        "    return video_features"
      ],
      "metadata": {
        "id": "ZwcbTrTZ94hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess text data\n",
        "def load_and_preprocess_text(transcription_path):\n",
        "    if not os.path.exists(transcription_path):\n",
        "        print(f\"Error: Transcription file {transcription_path} does not exist.\")\n",
        "        return \"\"\n",
        "\n",
        "    with open(transcription_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text"
      ],
      "metadata": {
        "id": "6LENewHBvEvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists for dataset\n",
        "video_features = []\n",
        "text_data = []\n",
        "gesture_data = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "3NWL6jj-vMQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "for idx, row in gesture_annotations.iterrows():\n",
        "    clip_id = row[clip_id_column]\n",
        "    video_file = os.path.join(video_folder, clip_id)\n",
        "    transcription_file = os.path.join(transcription_folder, clip_id.replace('.mp4', '.txt'))\n",
        "\n",
        "    # Extract video features\n",
        "    video_feat = extract_video_features(video_file, cnn_model)\n",
        "    if video_feat is not None:\n",
        "        video_features.append(video_feat)\n",
        "    else:\n",
        "        print(f\"Skipping {video_file} due to extraction issues.\")\n",
        "        continue\n",
        "\n",
        "    # Load and preprocess text\n",
        "    text = load_and_preprocess_text(transcription_file)\n",
        "    if text:\n",
        "        text_data.append(text)\n",
        "    else:\n",
        "        print(f\"Skipping {transcription_file} due to loading issues.\")\n",
        "        continue\n",
        "\n",
        "    # Get gesture data\n",
        "    gestures = row[1:-1].values  # Adjust index slicing if necessary\n",
        "    gesture_data.append(gestures)\n",
        "\n",
        "    # Get label\n",
        "    label = row[label_column]\n",
        "    labels.append(label)\n",
        "\n",
        "# Ensure all entries in text_data are strings\n",
        "text_data = [str(text) for text in text_data]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uRFdDhYvP4B",
        "outputId": "4df97580-41ab-4c7a-fe95-1c3d36bd626e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 19s 19s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "1/1 [==============================] - 19s 19s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 23s 23s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 19s 19s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 22s 22s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_051.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_051.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_052.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_052.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_053.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_053.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_054.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_054.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_055.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_055.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_056.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_056.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_057.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_057.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_058.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_058.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_059.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_059.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_060.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_060.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_061.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_lie_061.mp4 due to extraction issues.\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 19s 19s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 19s 19s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 20s 20s/step\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "1/1 [==============================] - 16s 16s/step\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_051.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_051.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_052.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_052.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_053.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_053.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_054.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_054.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_055.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_055.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_056.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_056.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_057.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_057.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_058.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_058.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_059.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_059.mp4 due to extraction issues.\n",
            "Error: Could not open video file /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_060.mp4\n",
            "Skipping /content/drive/MyDrive/RealLifeDeceptionDetection.2016/Real-life_Deception_Detection_2016/Clips/trial_truth_060.mp4 due to extraction issues.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert string labels to integers\n",
        "label_map = {'deceptive': 0, 'truthful': 1}\n",
        "labels = [label_map[label] for label in labels]\n",
        "# Convert lists to numpy arrays if they are not empty\n",
        "if len(video_features) > 0:\n",
        "    video_features = np.array(video_features, dtype='float32')\n",
        "if len(gesture_data) > 0:\n",
        "    gesture_data = np.array(gesture_data, dtype='float32')\n",
        "if len(labels) > 0:\n",
        "    labels = np.array(labels, dtype='int32')"
      ],
      "metadata": {
        "id": "lPRaaemN7aYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "sequences = tokenizer.texts_to_sequences(text_data)\n",
        "word_index = tokenizer.word_index\n",
        "text_data = pad_sequences(sequences, maxlen=100)  # MAX_SEQUENCE_LENGTH\n",
        "text_data = np.array(text_data, dtype='float32')"
      ],
      "metadata": {
        "id": "YEbwlm4J8AXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shapes and data types\n",
        "print(\"Video features shape:\", video_features.shape, \"dtype:\", video_features.dtype)\n",
        "print(\"Text data shape:\", text_data.shape, \"dtype:\", text_data.dtype)\n",
        "print(\"Gesture data shape:\", gesture_data.shape, \"dtype:\", gesture_data.dtype)\n",
        "print(\"Labels shape:\", labels.shape, \"dtype:\", labels.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-ID8N6w8EfH",
        "outputId": "9f834338-db83-4179-e96c-9ab311ec3137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video features shape: (100, 25088) dtype: float32\n",
            "Text data shape: (100, 100) dtype: float32\n",
            "Gesture data shape: (100, 39) dtype: float32\n",
            "Labels shape: (100,) dtype: int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplified model for initial testing\n",
        "text_input = Input(shape=(100,), name='text_input')  # MAX_SEQUENCE_LENGTH\n",
        "embedding = Embedding(len(word_index) + 1, 100)(text_input)  # EMBEDDING_DIM\n",
        "rnn_output = LSTM(128)(embedding)\n",
        "gesture_input = Input(shape=(gesture_data.shape[1],), name='gesture_input')\n",
        "video_input = Input(shape=(video_features.shape[1],), name='video_input')\n",
        "\n",
        "merged = Concatenate()([video_input, rnn_output, gesture_input])\n",
        "dense = Dense(128, activation='relu')(merged)\n",
        "output = Dense(2, activation='softmax')(dense)  # NUM_CLASSES\n",
        "\n",
        "model = Model(inputs=[video_input, text_input, gesture_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw38TRE-8IiF",
        "outputId": "5f42dc7e-ffc4-426e-acd3-d83a5da943a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text_input (InputLayer)     [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 100, 100)             133800    ['text_input[0][0]']          \n",
            "                                                                                                  \n",
            " video_input (InputLayer)    [(None, 25088)]              0         []                            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 128)                  117248    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " gesture_input (InputLayer)  [(None, 39)]                 0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 25255)                0         ['video_input[0][0]',         \n",
            "                                                                     'lstm[0][0]',                \n",
            "                                                                     'gesture_input[0][0]']       \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  3232768   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 2)                    258       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3484074 (13.29 MB)\n",
            "Trainable params: 3484074 (13.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example training (use actual data instead of placeholders)\n",
        "history=model.fit([video_features, text_data, gesture_data], labels, epochs=30, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ol4JZcx8QRN",
        "outputId": "2eb66362-4ef3-4c83-c9a1-48279bd317db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "3/3 [==============================] - 1s 444ms/step - loss: 1.8654e-04 - accuracy: 1.0000 - val_loss: 2.2981 - val_accuracy: 0.5500\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 2s 638ms/step - loss: 1.7410e-04 - accuracy: 1.0000 - val_loss: 2.3235 - val_accuracy: 0.5500\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 1s 397ms/step - loss: 1.6337e-04 - accuracy: 1.0000 - val_loss: 2.3459 - val_accuracy: 0.5000\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 1s 476ms/step - loss: 1.5192e-04 - accuracy: 1.0000 - val_loss: 2.3631 - val_accuracy: 0.5000\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 1s 434ms/step - loss: 1.4269e-04 - accuracy: 1.0000 - val_loss: 2.3779 - val_accuracy: 0.5000\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 1.3264e-04 - accuracy: 1.0000 - val_loss: 2.3945 - val_accuracy: 0.5000\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 1s 187ms/step - loss: 1.2450e-04 - accuracy: 1.0000 - val_loss: 2.4089 - val_accuracy: 0.5000\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 1s 190ms/step - loss: 1.1796e-04 - accuracy: 1.0000 - val_loss: 2.4299 - val_accuracy: 0.5000\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 1s 183ms/step - loss: 1.1133e-04 - accuracy: 1.0000 - val_loss: 2.4533 - val_accuracy: 0.5000\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 1s 184ms/step - loss: 1.0506e-04 - accuracy: 1.0000 - val_loss: 2.4793 - val_accuracy: 0.5000\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 1s 195ms/step - loss: 1.0009e-04 - accuracy: 1.0000 - val_loss: 2.5033 - val_accuracy: 0.5000\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 9.4834e-05 - accuracy: 1.0000 - val_loss: 2.5238 - val_accuracy: 0.5000\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 1s 192ms/step - loss: 9.0820e-05 - accuracy: 1.0000 - val_loss: 2.5493 - val_accuracy: 0.5000\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 8.7014e-05 - accuracy: 1.0000 - val_loss: 2.5742 - val_accuracy: 0.5000\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 1s 203ms/step - loss: 8.3070e-05 - accuracy: 1.0000 - val_loss: 2.5982 - val_accuracy: 0.5000\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 1s 167ms/step - loss: 7.9955e-05 - accuracy: 1.0000 - val_loss: 2.6239 - val_accuracy: 0.5000\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 1s 190ms/step - loss: 7.6569e-05 - accuracy: 1.0000 - val_loss: 2.6472 - val_accuracy: 0.5000\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 1s 184ms/step - loss: 7.3626e-05 - accuracy: 1.0000 - val_loss: 2.6734 - val_accuracy: 0.4500\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 1s 196ms/step - loss: 7.1145e-05 - accuracy: 1.0000 - val_loss: 2.6980 - val_accuracy: 0.4500\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 6.8064e-05 - accuracy: 1.0000 - val_loss: 2.7224 - val_accuracy: 0.4500\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 1s 187ms/step - loss: 6.6057e-05 - accuracy: 1.0000 - val_loss: 2.7475 - val_accuracy: 0.4500\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 6.2929e-05 - accuracy: 1.0000 - val_loss: 2.7709 - val_accuracy: 0.4500\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 6.1224e-05 - accuracy: 1.0000 - val_loss: 2.7914 - val_accuracy: 0.4500\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 5.8724e-05 - accuracy: 1.0000 - val_loss: 2.8112 - val_accuracy: 0.4500\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 5.6691e-05 - accuracy: 1.0000 - val_loss: 2.8315 - val_accuracy: 0.4500\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 5.5023e-05 - accuracy: 1.0000 - val_loss: 2.8550 - val_accuracy: 0.4000\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 1s 296ms/step - loss: 5.3024e-05 - accuracy: 1.0000 - val_loss: 2.8771 - val_accuracy: 0.4000\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 5.1119e-05 - accuracy: 1.0000 - val_loss: 2.8953 - val_accuracy: 0.4000\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 1s 196ms/step - loss: 4.9590e-05 - accuracy: 1.0000 - val_loss: 2.9113 - val_accuracy: 0.4000\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 1s 189ms/step - loss: 4.7996e-05 - accuracy: 1.0000 - val_loss: 2.9301 - val_accuracy: 0.4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model and calculate precision, recall, and f1 score\n",
        "from sklearn.metrics import accuracy_score\n",
        "def evaluate_model(model, video_features, text_data, gesture_data, labels):\n",
        "    predictions = model.predict([video_features, text_data, gesture_data])\n",
        "    y_pred = np.argmax(predictions, axis=1)\n",
        "    precision = precision_score(labels, y_pred, average='weighted')\n",
        "    recall = recall_score(labels, y_pred, average='weighted')\n",
        "    f1 = f1_score(labels, y_pred, average='weighted')\n",
        "    accuracy = accuracy_score(labels, y_pred) # Calculate accuracy\n",
        "    return precision, recall, f1, accuracy\n"
      ],
      "metadata": {
        "id": "1I_kUIbm8eMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, f1, accuracy = evaluate_model(model, video_features, text_data, gesture_data, labels)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUcMLO6G8htd",
        "outputId": "74b000f0-dd67-4ee3-a123-847e8207ccb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 36ms/step\n",
            "Accuracy: 0.88\n",
            "Precision: 0.9032258064516128\n",
            "Recall: 0.88\n",
            "F1 Score: 0.8782467532467533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(history.history.keys())\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Model Performance Metrics')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "2UPlebom4Zak",
        "outputId": "68332d7a-4b62-45e2-fab7-e2b932142c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}